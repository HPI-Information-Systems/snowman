/* tslint:disable */
/* eslint-disable */
/**
 * Snowman API
 * _This document describes the REST API of the snowman data matching benchmark tool._  Comparing data matching algorithms is still an unsolved topic in both industry and research.  With snowman, developers and researchers will be able to compare the performance of different data matching  solutions or improve new algorithms. 
 *
 * The version of the OpenAPI document: 1.0.0
 * Contact: snowman@groups.sap.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import {
    ExperimentIntersection,
    ExperimentIntersectionFromJSON,
    ExperimentIntersectionToJSON,
    ExperimentIntersectionCount,
    ExperimentIntersectionCountFromJSON,
    ExperimentIntersectionCountToJSON,
    ExperimentIntersectionMode,
    ExperimentIntersectionModeFromJSON,
    ExperimentIntersectionModeToJSON,
    Metric,
    MetricFromJSON,
    MetricToJSON,
} from '../models';

export interface CalculateExperimentIntersectionCountRequest {
    requestBody: Array<object>;
    mode?: ExperimentIntersectionMode;
}

export interface CalculateExperimentIntersectionRecordsRequest {
    requestBody: Array<object>;
    startAt?: number;
    limit?: number;
    sortBy?: string;
    mode?: ExperimentIntersectionMode;
}

export interface GetBinaryMetricsRequest {
    experimentId1: number;
    experimentId2: number;
    similarityThresholdExperiment1?: number;
    similarityAttributeExperiment1?: string;
    similarityThresholdExperiment2?: number;
    similarityAttributeExperiment2?: string;
}

/**
 * 
 */
export class BenchmarkApi extends runtime.BaseAPI {

    /**
     * intersects multiple experiments and returns the counts of the number of records. This can be used to calculate the confusion-matrix
     * Triggers the comparison of multiple experiments and returns tuples classified as false_negative, etc. and limited by limit
     */
    async calculateExperimentIntersectionCountRaw(requestParameters: CalculateExperimentIntersectionCountRequest): Promise<runtime.ApiResponse<ExperimentIntersectionCount>> {
        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling calculateExperimentIntersectionCount.');
        }

        const queryParameters: any = {};

        if (requestParameters.mode !== undefined) {
            queryParameters['mode'] = requestParameters.mode;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/benchmark/experiment-intersection/count`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        });

        return new runtime.JSONApiResponse(response, (jsonValue) => ExperimentIntersectionCountFromJSON(jsonValue));
    }

    /**
     * intersects multiple experiments and returns the counts of the number of records. This can be used to calculate the confusion-matrix
     * Triggers the comparison of multiple experiments and returns tuples classified as false_negative, etc. and limited by limit
     */
    async calculateExperimentIntersectionCount(requestParameters: CalculateExperimentIntersectionCountRequest): Promise<ExperimentIntersectionCount> {
        const response = await this.calculateExperimentIntersectionCountRaw(requestParameters);
        return await response.value();
    }

    /**
     * intersects multiple experiments and returns the resulting records. This can be used to calculate the confusion-matrix. Up to now exactly two experiment objects are required. The first one represents the groundTruth, the second one the predicted experiment.
     * Triggers the comparison of multiple experiments and returns tuples classified as false_negative, etc. and limited by limit
     */
    async calculateExperimentIntersectionRecordsRaw(requestParameters: CalculateExperimentIntersectionRecordsRequest): Promise<runtime.ApiResponse<ExperimentIntersection>> {
        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling calculateExperimentIntersectionRecords.');
        }

        const queryParameters: any = {};

        if (requestParameters.startAt !== undefined) {
            queryParameters['startAt'] = requestParameters.startAt;
        }

        if (requestParameters.limit !== undefined) {
            queryParameters['limit'] = requestParameters.limit;
        }

        if (requestParameters.sortBy !== undefined) {
            queryParameters['sortBy'] = requestParameters.sortBy;
        }

        if (requestParameters.mode !== undefined) {
            queryParameters['mode'] = requestParameters.mode;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/benchmark/experiment-intersection/records`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        });

        return new runtime.JSONApiResponse(response, (jsonValue) => ExperimentIntersectionFromJSON(jsonValue));
    }

    /**
     * intersects multiple experiments and returns the resulting records. This can be used to calculate the confusion-matrix. Up to now exactly two experiment objects are required. The first one represents the groundTruth, the second one the predicted experiment.
     * Triggers the comparison of multiple experiments and returns tuples classified as false_negative, etc. and limited by limit
     */
    async calculateExperimentIntersectionRecords(requestParameters: CalculateExperimentIntersectionRecordsRequest): Promise<ExperimentIntersection> {
        const response = await this.calculateExperimentIntersectionRecordsRaw(requestParameters);
        return await response.value();
    }

    /**
     * Compares two experiments and returns binary metrics
     */
    async getBinaryMetricsRaw(requestParameters: GetBinaryMetricsRequest): Promise<runtime.ApiResponse<Array<Metric>>> {
        if (requestParameters.experimentId1 === null || requestParameters.experimentId1 === undefined) {
            throw new runtime.RequiredError('experimentId1','Required parameter requestParameters.experimentId1 was null or undefined when calling getBinaryMetrics.');
        }

        if (requestParameters.experimentId2 === null || requestParameters.experimentId2 === undefined) {
            throw new runtime.RequiredError('experimentId2','Required parameter requestParameters.experimentId2 was null or undefined when calling getBinaryMetrics.');
        }

        const queryParameters: any = {};

        if (requestParameters.similarityThresholdExperiment1 !== undefined) {
            queryParameters['similarityThreshold_experiment1'] = requestParameters.similarityThresholdExperiment1;
        }

        if (requestParameters.similarityAttributeExperiment1 !== undefined) {
            queryParameters['similarityAttribute_experiment1'] = requestParameters.similarityAttributeExperiment1;
        }

        if (requestParameters.similarityThresholdExperiment2 !== undefined) {
            queryParameters['similarityThreshold_experiment2'] = requestParameters.similarityThresholdExperiment2;
        }

        if (requestParameters.similarityAttributeExperiment2 !== undefined) {
            queryParameters['similarityAttribute_experiment2'] = requestParameters.similarityAttributeExperiment2;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/benchmark/{experimentId1}/{experimentId2}/metrics`.replace(`{${"experimentId1"}}`, encodeURIComponent(String(requestParameters.experimentId1))).replace(`{${"experimentId2"}}`, encodeURIComponent(String(requestParameters.experimentId2))),
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        });

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(MetricFromJSON));
    }

    /**
     * Compares two experiments and returns binary metrics
     */
    async getBinaryMetrics(requestParameters: GetBinaryMetricsRequest): Promise<Array<Metric>> {
        const response = await this.getBinaryMetricsRaw(requestParameters);
        return await response.value();
    }

}
